{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documented-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import glob\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import pickle\n",
    "import requests\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "julian-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algunos de acá deberían venir del entorno\n",
    "SOURCE_DIR = os.path.abspath('dataset')\n",
    "SEARCHED_EXTENSIONS = [\"txt\"]\n",
    "\n",
    "# Dataset data\n",
    "DATASET_TARGET_FILE=os.path.abspath('dataset.data')\n",
    "DATASET_NAME = '20NewsGroups'\n",
    "DATASET_DESCRIPTION = \"Dataset de 20NewsGroup: http://qwone.com/~jason/20Newsgroups\"\n",
    "DATASET_TEXT_LABEL = \"data\"\n",
    "DATASET_OBSERVATIONS = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "therapeutic-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    PERMITTED_CHARS = \"0123456789abcdefghijklmnopqrstuvwxyz_-. \" \n",
    "    text = text.lower()\n",
    "    text = \"\".join(c for c in text if c in PERMITTED_CHARS)\n",
    "    text = text.replace(\" \", \"_\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endless-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirs_dict(dir_path):\n",
    "    result = {}\n",
    "    subdir_names = [o for o in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path,o))]\n",
    "    for subdir_name in subdir_names:\n",
    "        key = clean_text(subdir_name)\n",
    "        result[key] = os.path.join(dir_path, subdir_name)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divine-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfiles_with_extensions(source_path, extensions):\n",
    "    dir_contents = os.listdir(source_path)\n",
    "    files = []\n",
    "    for content in dir_contents:\n",
    "        content_path = os.path.join(source_path, content)\n",
    "        if os.path.isdir(content_path):\n",
    "            files = files + get_subfiles_with_extensions(content_path, extensions)\n",
    "        else:\n",
    "            for extension in extensions:\n",
    "                if content_path.endswith(extension):\n",
    "                    files.append(content_path)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "completed-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_to_base64(filepath):\n",
    "    file = open(filepath, 'rb')\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    raw_base64 = base64.b64encode(data) \n",
    "    return raw_base64.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171d8457-4324-43c9-a7d2-cc25c63d4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "            return file_content\n",
    "    except:\n",
    "        print(f'Cannot read file {filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tribal-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_with_pickle(file_path, object_to_save):\n",
    "    file = open(file_path, 'wb')\n",
    "    picklestring = pickle.dumps(object_to_save, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    file.write(picklestring)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "religious-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(source_path, encoding = \"utf8\"):\n",
    "    subdirs_dictionary = get_subdirs_dict(source_path)\n",
    "    categories = subdirs_dictionary.keys()\n",
    "    data = {DATASET_TEXT_LABEL:[]}\n",
    "    extracted_count = 0\n",
    "    for category in categories:\n",
    "        data[category] = []\n",
    "    for subdir_category, subdir_path in subdirs_dictionary.items():\n",
    "        subdir_category = clean_text(subdir_category)\n",
    "        subfiles = get_subfiles_with_extensions(subdir_path, SEARCHED_EXTENSIONS)\n",
    "        for subfile in subfiles:\n",
    "            file_base64 = convert_file_to_base64(subfile)\n",
    "            text_content = read_file(subfile) \n",
    "            data[DATASET_TEXT_LABEL].append(text_content)\n",
    "            for specific_category in categories:\n",
    "                category_value = 1 if specific_category == subdir_category else 0\n",
    "                data[specific_category].append(category_value)\n",
    "            extracted_count += 1\n",
    "            print(f'Extracted {extracted_count} files...', sep=\" \", end=\"\\r\", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    print(\"\")\n",
    "    print(f'Extracted all files...', sep=\" \", end=\"\\r\", flush=True)\n",
    "    return pandas.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "direct-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_file(target_file, dataframe):\n",
    "    file_content = {\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"description\": DATASET_DESCRIPTION,\n",
    "        \"date\": datetime.datetime.now(),\n",
    "        \"text_label\": DATASET_TEXT_LABEL,\n",
    "        \"observations\": DATASET_OBSERVATIONS,\n",
    "        \"dataframe\": dataframe\n",
    "    }\n",
    "    export_with_pickle(target_file, file_content)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civil-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 64 files...\r"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd1 in position 1162: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSOURCE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display(dataframe)\n",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m, in \u001b[0;36mgenerate_dataframe\u001b[1;34m(source_path, encoding)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfile \u001b[38;5;129;01min\u001b[39;00m subfiles:\n\u001b[0;32m     12\u001b[0m     file_base64 \u001b[38;5;241m=\u001b[39m convert_file_to_base64(subfile)\n\u001b[1;32m---> 13\u001b[0m     text_content \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubfile\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     14\u001b[0m     data[DATASET_TEXT_LABEL]\u001b[38;5;241m.\u001b[39mappend(text_content)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m specific_category \u001b[38;5;129;01min\u001b[39;00m categories:\n",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(filepath):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 3\u001b[0m         file_content \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m file_content\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd1 in position 1162: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "dataframe = generate_dataframe(SOURCE_DIR)\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_file(DATASET_TARGET_FILE, dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
